{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Risk-Return Analysis and Portfolio Optimization with OpenBB\n",
    "===========================================================\n",
    "#### Description\n",
    "This notebook demonstrates advanced techniques for risk-return analysis and portfolio optimization using OpenBB. We'll explore various asset classes, implement modern portfolio theory, and utilize OpenBB's extensive financial analysis capabilities. This comprehensive guide covers:\n",
    "\n",
    "1. Data collection and preprocessing\n",
    "2. Exploratory data analysis with visualizations\n",
    "3. Risk and return calculations\n",
    "4. Efficient frontier computation\n",
    "5. Portfolio optimization techniques\n",
    "6. Advanced risk metrics (VaR, CVaR)\n",
    "7. Performance attribution\n",
    "8. Scenario analysis and stress testing\n",
    "\n",
    "By the end of this notebook, you'll have a deep understanding of how to use OpenBB for sophisticated financial analysis and portfolio management.\n",
    "\n",
    "#### Author\n",
    "[Amit Kumar](https://github.com/HmbleCreator)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OpenBB-Finance/OpenBB/blob/develop/examples/[Notebook_Name].ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook in Colab, you can run the following command to install the OpenBB Platform:\n",
    "\n",
    "```python\n",
    "!pip install openbb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openbb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "To run this notebook, you'll need to install the following dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openbb pandas numpy matplotlib seaborn scipy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from openbb import obb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting style\n",
    "plt.style.use('default')  # Use the default Matplotlib style\n",
    "sns.set_theme(style=\"whitegrid\")  # Set Seaborn style\n",
    "sns.set_palette(\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openbb import obb\n",
    "obb.account.login(pat=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRoX3Rva2VuIjoiTk5qcWd2bFhEQ1RqZFFTbFZzSTZqNkRwYVA4aDVkSDJLWmdMUmV1ZCIsImV4cCI6MTc1OTU3MjIxMX0.Zb4KseRt5kkRbwy6JsUgFX6dV2v5YampXfCRAGwQ5K4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Preprocessing\n",
    "Let's collect historical data for a diverse set of asset classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openbb import obb\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Define asset classes and their tickers\n",
    "assets = {\n",
    "    'US Large Cap': 'SPY',\n",
    "    'US Small Cap': 'IWM',\n",
    "    'International Developed': 'EFA',\n",
    "    'Emerging Markets': 'EEM',\n",
    "    'US Aggregate Bonds': 'AGG',\n",
    "    'US Treasury Bonds': 'TLT',\n",
    "    'Real Estate': 'VNQ',\n",
    "    'Gold': 'GLD',\n",
    "    'Commodities': 'DBC'\n",
    "}\n",
    "\n",
    "# Set date range\n",
    "end_date = datetime.now().date()\n",
    "start_date = end_date - timedelta(days=365)  # Adjusted to 1 year for testing\n",
    "\n",
    "# Function to fetch historical data with retries\n",
    "def fetch_historical_data(ticker, retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            # Fetch historical data using the correct function and parameters\n",
    "            historical_data = obb.equity.price.historical(ticker)\n",
    "            \n",
    "            # Convert the OBBject to a DataFrame using the to_dataframe() method\n",
    "            df = historical_data.to_dataframe()\n",
    "            \n",
    "            # Check if DataFrame is empty and return it if not\n",
    "            if df is not None and not df.empty:\n",
    "                return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for {ticker}: {str(e)}\")\n",
    "            time.sleep(2)  # Wait before retrying\n",
    "            \n",
    "    return None\n",
    "\n",
    "# Fetch data and combine into a single DataFrame\n",
    "combined_data = {}\n",
    "for asset_name, ticker in assets.items():\n",
    "    df = fetch_historical_data(ticker)\n",
    "    \n",
    "    if df is not None and not df.empty:\n",
    "        # Store closing prices with asset name as key\n",
    "        combined_data[asset_name] = df['close']\n",
    "    else:\n",
    "        print(f\"No data returned for {asset_name} ({ticker}).\")\n",
    "\n",
    "# Combine all asset closing prices into a single DataFrame\n",
    "df_combined = pd.DataFrame(combined_data)\n",
    "\n",
    "# Check if we have any data\n",
    "if df_combined.empty:\n",
    "    raise ValueError(\"No data was successfully retrieved. Please check your tickers and date range.\")\n",
    "\n",
    "# Calculate daily returns with specified fill method to avoid FutureWarning\n",
    "returns = df_combined.pct_change(fill_method=None).dropna()\n",
    "\n",
    "# Display the combined DataFrame for better readability\n",
    "print(\"Combined Closing Prices:\")\n",
    "print(df_combined.head())  # Display first few rows of closing prices\n",
    "\n",
    "print(\"\\nDaily Returns:\")\n",
    "print(returns.head())  # Display first few rows of returns\n",
    "\n",
    "\n",
    "# Export the combined DataFrame to an Excel file\n",
    "output_file = \"financial_data.xlsx\"\n",
    "df_combined.to_excel(output_file)\n",
    "\n",
    "print(f\"Data exported successfully to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "Let's visualize our data to better understand the relationships between different asset classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def fig_to_base64(fig):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    return base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(returns.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Asset Returns')\n",
    "heatmap_base64 = fig_to_base64(plt.gcf())\n",
    "plt.close()\n",
    "\n",
    "# Cumulative returns plot\n",
    "cumulative_returns = (1 + returns).cumprod()\n",
    "plt.figure(figsize=(12, 6))\n",
    "cumulative_returns.plot()\n",
    "plt.title('Cumulative Returns of Asset Classes')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "cumulative_returns_base64 = fig_to_base64(plt.gcf())\n",
    "plt.close()\n",
    "\n",
    "# Display images\n",
    "display(HTML(f'<img src=\"data:image/png;base64,{heatmap_base64}\" />'))\n",
    "display(HTML(f'<img src=\"data:image/png;base64,{cumulative_returns_base64}\" />'))\n",
    "\n",
    "# Store base64 strings in variables (optional, for debugging or later use)\n",
    "heatmap_data = f'\"image/png\": \"{heatmap_base64[:50]}...\"'\n",
    "cumulative_returns_data = f'\"image/png\": \"{cumulative_returns_base64[:50]}...\"'\n",
    "\n",
    "print(\"Heatmap data (preview):\", heatmap_data)\n",
    "print(\"Cumulative returns data (preview):\", cumulative_returns_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk and Return Calculations\n",
    "Now let's calculate key risk and return metrics for each asset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check if returns DataFrame is not empty before calculations\n",
    "if not returns.empty:\n",
    "    # Calculate annualized returns and volatility\n",
    "    annual_returns = returns.mean() * 252\n",
    "    annual_volatility = returns.std() * np.sqrt(252)\n",
    "\n",
    "    # Calculate Sharpe Ratio (assuming risk-free rate of 2%)\n",
    "    risk_free_rate = 0.02\n",
    "    sharpe_ratio = (annual_returns - risk_free_rate) / annual_volatility\n",
    "\n",
    "    # Combine metrics into a DataFrame\n",
    "    risk_return_metrics = pd.DataFrame({\n",
    "        'Return': annual_returns,\n",
    "        'Volatility': annual_volatility,\n",
    "        'Sharpe Ratio': sharpe_ratio\n",
    "    })\n",
    "\n",
    "    # Sort and display the metrics\n",
    "    print(risk_return_metrics.sort_values('Sharpe Ratio', ascending=False))\n",
    "\n",
    "    # Visualize risk-return tradeoff\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(data=risk_return_metrics, x='Volatility', y='Return', size='Sharpe Ratio', \n",
    "                    sizes=(50, 500), legend='brief', hue='Sharpe Ratio', palette='viridis')\n",
    "\n",
    "    # Annotate points with asset names\n",
    "    for i, asset in enumerate(risk_return_metrics.index):\n",
    "        plt.annotate(asset, \n",
    "                     (risk_return_metrics['Volatility'][i], risk_return_metrics['Return'][i]), \n",
    "                     xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "    plt.title('Risk-Return Tradeoff of Various Asset Classes')\n",
    "    plt.xlabel('Risk (Annualized Volatility)')\n",
    "    plt.ylabel('Return (Annualized)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No return data available for calculations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Efficient Frontier Computation\n",
    "Let's compute the efficient frontier to understand the optimal risk-return tradeoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def portfolio_performance(weights, returns):\n",
    "    portfolio_return = np.sum(returns.mean() * weights) * 252  # Annualized return\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))  # Annualized volatility\n",
    "    return portfolio_return, portfolio_volatility\n",
    "\n",
    "def negative_sharpe_ratio(weights, returns, risk_free_rate):\n",
    "    p_return, p_volatility = portfolio_performance(weights, returns)\n",
    "    return -(p_return - risk_free_rate) / p_volatility  # Negative Sharpe Ratio for minimization\n",
    "\n",
    "def calculate_efficient_frontier(returns, num_portfolios=1000):\n",
    "    num_assets = len(returns.columns)\n",
    "    results = np.zeros((3, num_portfolios))\n",
    "    \n",
    "    for i in range(num_portfolios):\n",
    "        weights = np.random.random(num_assets)\n",
    "        weights /= np.sum(weights)  # Normalize weights\n",
    "        p_return, p_volatility = portfolio_performance(weights, returns)\n",
    "        results[0,i] = p_return\n",
    "        results[1,i] = p_volatility\n",
    "        results[2,i] = p_return / p_volatility  # Sharpe Ratio\n",
    "    \n",
    "    return results.T\n",
    "\n",
    "# Calculate efficient frontier\n",
    "efficient_frontier = calculate_efficient_frontier(returns)\n",
    "\n",
    "# Find the optimal portfolio (maximum Sharpe ratio)\n",
    "num_assets = len(returns.columns)\n",
    "risk_free_rate = 0.02  # Define risk-free rate if not already defined\n",
    "args = (returns, risk_free_rate)\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # Weights sum to 1\n",
    "bound = (0.0, 1.0)\n",
    "bounds = tuple(bound for asset in range(num_assets))\n",
    "\n",
    "result = minimize(negative_sharpe_ratio, num_assets*[1./num_assets], args=args,\n",
    "                  method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "optimal_weights = result.x\n",
    "optimal_return, optimal_volatility = portfolio_performance(optimal_weights, returns)\n",
    "\n",
    "# Plot efficient frontier\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(efficient_frontier[:,1], efficient_frontier[:,0], c=efficient_frontier[:,2], cmap='viridis')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Return')\n",
    "plt.title('Efficient Frontier')\n",
    "\n",
    "# Plot individual assets\n",
    "for i, asset in enumerate(returns.columns):\n",
    "    plt.scatter(risk_return_metrics.loc[asset, 'Volatility'], \n",
    "                risk_return_metrics.loc[asset, 'Return'], \n",
    "                marker='o', s=200, label=asset)\n",
    "\n",
    "# Plot optimal portfolio\n",
    "plt.scatter(optimal_volatility, optimal_return, c='red', s=200, marker='*', label='Optimal Portfolio')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Optimal Portfolio Weights:\")\n",
    "for asset, weight in zip(returns.columns, optimal_weights):\n",
    "    print(f\"{asset}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Risk Metrics\n",
    "Let's calculate Value at Risk (VaR) and Conditional Value at Risk (CVaR) for our optimal portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_var_cvar(returns, weights, confidence_level=0.95):\n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = np.sum(returns * weights, axis=1)\n",
    "    \n",
    "    # Calculate VaR\n",
    "    var = np.percentile(portfolio_returns, 100 * (1 - confidence_level))\n",
    "    \n",
    "    # Calculate CVaR\n",
    "    cvar = portfolio_returns[portfolio_returns <= var].mean()\n",
    "    \n",
    "    return var, cvar\n",
    "\n",
    "# Check if returns DataFrame is not empty before proceeding\n",
    "if not returns.empty and optimal_weights is not None:\n",
    "    # Calculate optimal portfolio returns\n",
    "    optimal_portfolio_returns = np.sum(returns * optimal_weights, axis=1)\n",
    "\n",
    "    # Calculate 95% VaR and CVaR\n",
    "    var_95, cvar_95 = calculate_var_cvar(returns, optimal_weights)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"95% VaR: {var_95:.4f}\")\n",
    "    print(f\"95% CVaR: {cvar_95:.4f}\")\n",
    "\n",
    "    # Visualize VaR and CVaR\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(optimal_portfolio_returns, kde=True)\n",
    "    plt.axvline(var_95, color='r', linestyle='dashed', label='95% VaR')\n",
    "    plt.axvline(cvar_95, color='g', linestyle='dashed', label='95% CVaR')\n",
    "    plt.title('Distribution of Optimal Portfolio Returns with VaR and CVaR')\n",
    "    plt.xlabel('Daily Return')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Returns data or optimal weights are not available for calculations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scenario Analysis and Stress Testing\n",
    "Let's perform a simple scenario analysis to see how our optimal portfolio would perform under different market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scenario_analysis(weights, returns, scenarios):\n",
    "    # Calculate portfolio returns based on weights\n",
    "    portfolio_returns = np.sum(returns * weights, axis=1)\n",
    "    scenario_results = {}\n",
    "    \n",
    "    for scenario, shock in scenarios.items():\n",
    "        # Convert shock dictionary to a Series\n",
    "        shock_series = pd.Series(shock)\n",
    "        shocked_returns = returns + shock_series\n",
    "        \n",
    "        # Calculate scenario portfolio returns\n",
    "        scenario_portfolio_returns = np.sum(shocked_returns * weights, axis=1)\n",
    "        \n",
    "        # Store results for each scenario\n",
    "        scenario_results[scenario] = {\n",
    "            'Mean Return': scenario_portfolio_returns.mean(),\n",
    "            'Volatility': scenario_portfolio_returns.std(),\n",
    "            'VaR 95%': np.percentile(scenario_portfolio_returns, 5),\n",
    "            'CVaR 95%': scenario_portfolio_returns[scenario_portfolio_returns <= np.percentile(scenario_portfolio_returns, 5)].mean()\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(scenario_results).T\n",
    "\n",
    "# Define scenarios\n",
    "scenarios = {\n",
    "    'Base Case': {asset: 0 for asset in returns.columns},\n",
    "    'Market Crash': {asset: -0.3 for asset in returns.columns},\n",
    "    'Economic Boom': {asset: 0.2 for asset in returns.columns},\n",
    "    'Rising Interest Rates': {'US Aggregate Bonds': -0.1, 'US Treasury Bonds': -0.15},\n",
    "    'Commodity Boom': {'Gold': 0.25, 'Commodities': 0.3}\n",
    "}\n",
    "\n",
    "# Check if returns DataFrame is not empty before proceeding\n",
    "if not returns.empty:\n",
    "    # Assuming optimal_weights is defined and returns is your DataFrame of returns\n",
    "    optimal_weights = [0.2] * len(returns.columns)  # Example weights; adjust as necessary\n",
    "\n",
    "    # Perform scenario analysis\n",
    "    scenario_results = scenario_analysis(optimal_weights, returns, scenarios)\n",
    "    print(scenario_results)\n",
    "\n",
    "    # Visualize scenario analysis results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    scenario_results[['Mean Return', 'Volatility']].plot(kind='bar')\n",
    "    plt.title('Scenario Analysis: Mean Return and Volatility')\n",
    "    plt.xlabel('Scenario')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Returns data is not available for calculations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Attribution\n",
    "Performance attribution helps us understand which assets contributed most to our portfolio's performance. Let's implement a simple performance attribution analysis for our optimal portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def fig_to_base64(fig):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    return base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "\n",
    "def performance_attribution(weights, returns):\n",
    "    # Calculate portfolio return\n",
    "    portfolio_return = np.sum(returns.mean() * weights) * 252  # Annualized return\n",
    "    \n",
    "    # Calculate asset contribution to returns\n",
    "    asset_contribution = returns.mean() * weights * 252  # Annualized contribution\n",
    "    percent_contribution = asset_contribution / portfolio_return  # Contribution percentage\n",
    "    \n",
    "    # Create DataFrame for attribution data\n",
    "    attribution_data = pd.DataFrame({\n",
    "        'Weight': weights,\n",
    "        'Return': returns.mean() * 252,\n",
    "        'Contribution': asset_contribution,\n",
    "        'Percent Contribution': percent_contribution\n",
    "    })\n",
    "    return attribution_data.sort_values('Percent Contribution', ascending=False)\n",
    "\n",
    "# Check if returns DataFrame is not empty before proceeding\n",
    "if not returns.empty and optimal_weights is not None:\n",
    "    # Calculate performance attribution\n",
    "    attribution = performance_attribution(optimal_weights, returns)\n",
    "    print(attribution)\n",
    "    \n",
    "    # Visualize performance attribution\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    attribution['Percent Contribution'].plot(kind='bar', ax=ax)\n",
    "    ax.set_title('Performance Attribution of Optimal Portfolio')\n",
    "    ax.set_xlabel('Asset')\n",
    "    ax.set_ylabel('Percent Contribution to Return')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Convert plot to base64\n",
    "    plot_base64 = fig_to_base64(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Display the plot\n",
    "    display(HTML(f'<img src=\"data:image/png;base64,{plot_base64}\" />'))\n",
    "    \n",
    "    # Store base64 string in a variable (optional, for debugging or later use)\n",
    "    plot_data = f'\"image/png\": \"{plot_base64[:50]}...\"'\n",
    "    print(\"Plot data (preview):\", plot_data)\n",
    "else:\n",
    "    print(\"Returns data or optimal weights are not available for calculations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scenario Analysis and Stress Testing\n",
    "Now, let's expand on our previous scenario analysis to include more detailed stress testing. We'll define several economic scenarios and see how our portfolio performs under each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_scenario_analysis(weights, returns, scenarios):\n",
    "    portfolio_returns = np.sum(returns * weights, axis=1)\n",
    "    base_performance = {\n",
    "        'Mean Return': portfolio_returns.mean() * 252,\n",
    "        'Volatility': portfolio_returns.std() * np.sqrt(252),\n",
    "        'Sharpe Ratio': (portfolio_returns.mean() * 252 - risk_free_rate) / (portfolio_returns.std() * np.sqrt(252)),\n",
    "        'VaR 95%': np.percentile(portfolio_returns, 5) * np.sqrt(252),\n",
    "        'CVaR 95%': portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 5)].mean() * np.sqrt(252),\n",
    "        'Max Drawdown': (portfolio_returns.cumsum() - portfolio_returns.cumsum().cummax()).min()\n",
    "    }\n",
    "    \n",
    "    scenario_results = {'Base Case': base_performance}\n",
    "    \n",
    "    for scenario, shocks in scenarios.items():\n",
    "        shocked_returns = returns.copy()\n",
    "        for asset, shock in shocks.items():\n",
    "            shocked_returns[asset] += shock\n",
    "        \n",
    "        scenario_portfolio_returns = np.sum(shocked_returns * weights, axis=1)\n",
    "        scenario_results[scenario] = {\n",
    "            'Mean Return': scenario_portfolio_returns.mean() * 252,\n",
    "            'Volatility': scenario_portfolio_returns.std() * np.sqrt(252),\n",
    "            'Sharpe Ratio': (scenario_portfolio_returns.mean() * 252 - risk_free_rate) / (scenario_portfolio_returns.std() * np.sqrt(252)),\n",
    "            'VaR 95%': np.percentile(scenario_portfolio_returns, 5) * np.sqrt(252),\n",
    "            'CVaR 95%': scenario_portfolio_returns[scenario_portfolio_returns <= np.percentile(scenario_portfolio_returns, 5)].mean() * np.sqrt(252),\n",
    "            'Max Drawdown': (scenario_portfolio_returns.cumsum() - scenario_portfolio_returns.cumsum().cummax()).min()\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(scenario_results).T\n",
    "\n",
    "# Define more detailed scenarios\n",
    "detailed_scenarios = {\n",
    "    'Market Crash': {'US Large Cap': -0.4, 'US Small Cap': -0.5, 'International Developed': -0.35, 'Emerging Markets': -0.45, 'US Aggregate Bonds': 0.05, 'US Treasury Bonds': 0.1, 'Real Estate': -0.3, 'Gold': 0.15, 'Commodities': -0.25},\n",
    "    'Economic Boom': {'US Large Cap': 0.25, 'US Small Cap': 0.3, 'International Developed': 0.2, 'Emerging Markets': 0.35, 'US Aggregate Bonds': -0.05, 'US Treasury Bonds': -0.1, 'Real Estate': 0.2, 'Gold': -0.1, 'Commodities': 0.15},\n",
    "    'Rising Interest Rates': {'US Large Cap': -0.1, 'US Small Cap': -0.15, 'International Developed': -0.05, 'Emerging Markets': -0.1, 'US Aggregate Bonds': -0.2, 'US Treasury Bonds': -0.25, 'Real Estate': -0.15, 'Gold': -0.05, 'Commodities': 0.05},\n",
    "    'Geopolitical Tension': {'US Large Cap': -0.15, 'US Small Cap': -0.2, 'International Developed': -0.25, 'Emerging Markets': -0.3, 'US Aggregate Bonds': 0.1, 'US Treasury Bonds': 0.15, 'Real Estate': -0.1, 'Gold': 0.25, 'Commodities': 0.2},\n",
    "    'Tech Boom': {'US Large Cap': 0.3, 'US Small Cap': 0.35, 'International Developed': 0.2, 'Emerging Markets': 0.25, 'US Aggregate Bonds': -0.05, 'US Treasury Bonds': -0.1, 'Real Estate': 0.1, 'Gold': -0.05, 'Commodities': 0},\n",
    "}\n",
    "\n",
    "# Run detailed scenario analysis\n",
    "detailed_scenario_results = detailed_scenario_analysis(optimal_weights, returns, detailed_scenarios)\n",
    "print(detailed_scenario_results)\n",
    "\n",
    "# Visualize scenario analysis results\n",
    "plt.figure(figsize=(15, 10))\n",
    "detailed_scenario_results[['Mean Return', 'Volatility', 'Sharpe Ratio', 'VaR 95%', 'CVaR 95%']].plot(kind='bar', subplots=True, layout=(3,2), sharex=False, figsize=(15,20))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize max drawdown for each scenario\n",
    "plt.figure(figsize=(12, 6))\n",
    "detailed_scenario_results['Max Drawdown'].plot(kind='bar')\n",
    "plt.title('Max Drawdown Under Different Scenarios')\n",
    "plt.xlabel('Scenario')\n",
    "plt.ylabel('Max Drawdown')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
